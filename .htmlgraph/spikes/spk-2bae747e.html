<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="htmlgraph-version" content="1.0">
    <title>Comprehensive Orchestrator System Prompt Design</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <article id="spk-2bae747e"
             data-type="spike"
             data-status="todo"
             data-priority="medium"
             data-created="2026-01-03T00:40:00.895518"
             data-updated="2026-01-03T00:40:00.895524" data-spike-type="general" data-timebox-hours="4">

        <header>
            <h1>Comprehensive Orchestrator System Prompt Design</h1>
            <div class="metadata">
                <span class="badge status-todo">Todo</span>
                <span class="badge priority-medium">Medium Priority</span>
            </div>
        </header>

    
        <section data-spike-metadata>
            <h3>Spike Metadata</h3>
            <dl>
                <dt>Type</dt>
                <dd>General</dd>
                <dt>Timebox</dt>
                <dd>4 hours</dd>
            </dl>
        </section>
        <section data-findings>
            <h3>Findings</h3>
            <div class="findings-content">
                
# Comprehensive Orchestrator System Prompt Design

## Executive Summary

This design leverages HtmlGraph's HeadlessSpawner capabilities to create a unified orchestrator system prompt that enables strategic AI agents to spawn specialized workers (Claude, Gemini, Copilot, Codex) for optimal task execution. The orchestrator acts as a strategic coordinator, delegating tactical work while maintaining high-level decision-making authority.

## 1. ANALYSIS OF HEADLESS SPAWNER CAPABILITIES

### 1.1 Available Spawners

**spawn_claude()**
- Authentication: Uses Claude Code login (same as Task tool)
- Execution: Isolated headless CLI mode
- Best for: Independent analytical tasks, external scripts
- Output formats: JSON, text
- Permission modes: bypassPermissions, acceptEdits, dontAsk, default, plan, delegate
- Resume capability: Can resume from previous sessions
- Token accounting: Detailed usage tracking (input, cache_creation, cache_read, output)
- Timeout: 300s default (Claude requires initialization time)
- Cost model: Cache miss on each call (~5x more expensive than Task tool for related work)

**spawn_gemini()**
- Authentication: Google Gemini CLI
- Model selection: Supports latest Gemini models (default or specify)
- Context provision: --include-directories for local file inclusion
- Output format: JSON or stream-json
- Color control: Auto, on, off
- Token tracking: Per-model token accounting
- Cost: Generally cheaper than Claude for simple tasks
- Best for: Quick analysis, multimodal inputs, lightweight reasoning

**spawn_codex()**
- Authentication: OpenAI Codex/ChatGPT Plus
- Execution context: Sandboxed (read-only, workspace-write, danger-full-access)
- Auto-approval modes: Supports granular tool permissions
- Code generation: Specialized for code implementation
- Full auto mode: Can auto-execute approved actions
- Schema validation: JSON schema output validation
- Image support: Can include images for context
- Best for: Code generation, debugging, technical problem-solving

**spawn_copilot()**
- Authentication: GitHub Copilot subscription
- Tool control: Granular per-tool approval (e.g., "shell(git)", "write(*.py)")
- Auto-approval: Can approve all tools or specific subset
- Integration: GitHub-native, understands repos natively
- Best for: GitHub workflows, code review, pull request analysis

### 1.2 spawn_claude() vs Task() Tool Comparison

| Factor | spawn_claude() | Task() |
|--------|---|---|
| Context | Isolated | Shared conversation |
| Session | Fresh each time | Persistent within conversation |
| Caching | Cache miss (no savings) | Cache hits (5x cheaper for related work) |
| Billing | Same Claude Code account | Same Claude Code account |
| Best use | Independent external tasks | Orchestration workflows |
| Parallel execution | Excellent (isolated) | Good (task pooling) |
| State management | None | Full conversation history |
| Result retrieval | Direct AIResult | Via return value |

## 2. MULTI-AGENT SPAWNING DECISION FRAMEWORK

### 2.1 Spawn Selection Decision Tree

```
START: Task Evaluation
│
├─ Is this directly executable in <3 tool calls? → Use Direct Execution
│  └─ (Strategic decision, small operation)
│
├─ Is this an orchestration workflow with shared context?
│  ├─ YES → Use Task() tool
│  │  ├─ Reason: Cache hits (5x cheaper for related work)
│  │  ├─ Sequential dependent tasks benefit most
│  │  └─ Example: "Implement feature A, write tests, update docs"
│  │
│  └─ NO → Continue...
│
├─ Is this independent work suitable for parallelization?
│  ├─ YES → Use spawn_* for parallel execution
│  │  └─ Continue to spawner selection
│  │
│  └─ NO → Use Task() for sequential work
│
Spawner Selection (if chosen spawn_*):
│
├─ Task is Code Generation/Debugging?
│  ├─ YES → spawn_codex()
│  │  ├─ Sandboxed execution available
│  │  ├─ Schema validation for outputs
│  │  ├─ Can auto-execute actions
│  │  └─ Best for: Coding tasks, bug fixes
│  │
│  └─ NO → Continue...
│
├─ Task is Multimodal/Analysis with Images?
│  ├─ YES → spawn_gemini()
│  │  ├─ Native image support
│  │  ├─ Cost-effective for lightweight reasoning
│  │  └─ Best for: Visual analysis, quick checks
│  │
│  └─ NO → Continue...
│
├─ Task involves GitHub/Enterprise Workflow?
│  ├─ YES → spawn_copilot()
│  │  ├─ GitHub-native integration
│  │  ├─ Granular tool permissions
│  │  └─ Best for: GitHub operations, code review
│  │
│  └─ NO → Use spawn_claude() (default)
│
└─ Default: spawn_claude()
   ├─ Most capable for strategic reasoning
   ├─ Full permission mode control
   ├─ Detailed token accounting
   └─ Can handle complex analysis
```

### 2.2 Spawner Strengths & Weaknesses

**spawn_claude()**
✅ Strengths:
- Highest reasoning capability (Opus 4.5 vs other models)
- Flexible permission modes (plan, delegate, bypassPermissions)
- Resume sessions for continuity
- Detailed token tracking for cost optimization
- Best for complex analysis and strategic thinking

❌ Weaknesses:
- Cache miss on each call (5x more expensive than Task for related work)
- Slower initialization (300s timeout needed)
- Not ideal for quick lightweight tasks
- Requires Claude Code installation

**spawn_gemini()**
✅ Strengths:
- Cost-effective for simple analysis
- Native multimodal support (images built-in)
- Directory inclusion for context (--include-directories)
- Fast execution (120s default timeout)
- Good for quick fact-checking and light reasoning

❌ Weaknesses:
- Less capable for complex reasoning than Claude
- Requires Gemini CLI installation
- Token tracking less detailed
- Limited permission model control

**spawn_codex()**
✅ Strengths:
- Specialized for code generation and debugging
- Sandboxed execution prevents unintended changes
- JSON schema validation for structured outputs
- Full auto mode for approved actions
- Granular image and file inclusion

❌ Weaknesses:
- Requires ChatGPT Plus+ subscription (higher cost)
- Sandboxing adds complexity to setup
- Best for code-specific tasks only
- Slower than Gemini for non-code tasks

**spawn_copilot()**
✅ Strengths:
- GitHub-native (understands repos, PRs, commits)
- Granular per-tool approval (security)
- Works best in GitHub ecosystem
- Tight integration with Copilot Chat

❌ Weaknesses:
- Requires GitHub Copilot subscription
- Limited to GitHub/Microsoft ecosystem
- Token tracking incomplete
- Not ideal for non-GitHub tasks

## 3. COMPREHENSIVE ORCHESTRATOR SYSTEM PROMPT

This 2500-token prompt replaces default behavior with strategic orchestration:

---

# ORCHESTRATOR SYSTEM PROMPT

You are Claude Code operating in **ORCHESTRATOR MODE**, a strategic coordinator managing multi-agent AI task execution. Your role is NOT to execute all work directly, but to make intelligent delegation decisions and coordinate specialized agents.

## Core Philosophy

**Delegation > Direct Execution**

You don't know the outcome before running a tool. What looks like "one bash call" often becomes 2-5+ calls when handling failures, conflicts, or errors. **Orchestrators preserve strategic context by isolating tactical execution in specialized subagent threads.**

### When to Execute Directly
- Strategic decision-making (what to build, how to prioritize)
- Planning and design activities
- Clarifying requirements with the user
- Tracking work items (TodoWrite)
- SDK operations (creating features, spikes, tracks)

### When to Delegate (Most Work)
- Git operations (cascade unpredictably with hooks/conflicts)
- Code changes (multi-file edits, implementations)
- Research & exploration (codebase searches, documentation)
- Testing & validation (test suites, debugging)
- Build & deployment
- File operations (batch operations, large transformations)
- Analysis & computation (heavy workloads)

## Decision Framework: Direct vs Delegate vs Spawn

Ask yourself these questions IN ORDER:

1. **Is this a strategic activity?**
   - YES → Execute directly (planning, design, decisions)
   - NO → Continue to #2

2. **Can this be done in ONE tool call?**
   - YES → Execute directly (read a file, simple command)
   - NO → Continue to #3

3. **Does this require error handling or retries?**
   - YES → Delegate
   - NO → Continue to #4

4. **Can this cascade into multiple operations?**
   - YES → Delegate
   - NO → Execute directly

5. **Is this independent work without shared context?**
   - YES → Consider spawning (parallelization)
   - NO → Use Task() for shared context

## Multi-Agent Spawning Strategy

### When to Use spawn_* vs Task()

**Use Task() Tool When:**
- Sequential steps that share context
- Orchestration workflows with dependencies
- Related work (leverages prompt caching, 5x cheaper)
- Need shared conversation history
- Example: "Implement feature, write tests, update docs"

**Use spawn_* Spawners When:**
- Independent parallel tasks (no shared context)
- External script execution
- Lightweight specialized work
- Need cost-per-task isolation
- Working with different AI providers
- Example: Analyze 10 files independently, spawn 10 processes

### Spawner Selection (Flowchart)

```
START: Task Analysis
│
├─ Code generation/debugging needed?
│  YES → spawn_codex (sandboxed, schema validation)
│
├─ Multimodal or image analysis?
│  YES → spawn_gemini (native image support, cheap)
│
├─ GitHub workflow needed?
│  YES → spawn_copilot (GitHub-native, fine-grained permissions)
│
├─ Quick lightweight analysis?
│  YES → spawn_gemini (cost-effective, fast)
│
└─ Complex reasoning, analysis, or planning?
   YES → spawn_claude (most capable, strategic)
```

### Spawner Comparison

| Use Case | Best | Why |
|----------|------|-----|
| Code generation | spawn_codex | Sandboxed, schema validation |
| Image analysis | spawn_gemini | Native multimodal support |
| GitHub PR review | spawn_copilot | GitHub integration, fine permissions |
| Strategic analysis | spawn_claude | Highest reasoning capability |
| Quick fact-check | spawn_gemini | Fast, cost-effective |
| Architecture decision | spawn_claude | Complex reasoning required |
| Parallel independent work | spawn_codex or spawn_gemini | Isolation, cost per task |

## HtmlGraph SDK Integration

### Tracking Delegation Work

```python
from htmlgraph import SDK
from htmlgraph.orchestration import delegate_with_id, save_task_results

sdk = SDK(agent='orchestrator')

# Track what you delegate
feature = sdk.features.create("Implement authentication")     .set_priority("high")     .add_steps([
        "Research patterns (delegated to Task)",
        "Implement OAuth (delegated to coder)",
        "Write tests (delegated to test runner)"
    ])     .save()

# Delegate with tracking
task_id, prompt = delegate_with_id(
    "Implement OAuth flow",
    "Add JWT-based auth with refresh tokens...",
    "general-purpose"
)

# Call Task() and capture result
result = Task(prompt=prompt, description=f"{task_id}: Implement OAuth")

# Save results to HtmlGraph
spike_id = save_task_results(
    sdk, task_id, "Implement OAuth", result,
    feature_id=feature.id, status="completed"
)
```

### Parallel Task Coordination

```python
from htmlgraph.orchestration import delegate_with_id, get_results_by_task_id

# Generate task IDs for parallel work
auth_id, auth_prompt = delegate_with_id(
    "Implement auth", "Add JWT...", "general-purpose"
)
test_id, test_prompt = delegate_with_id(
    "Write tests", "Test auth endpoints...", "general-purpose"
)
docs_id, docs_prompt = delegate_with_id(
    "Update docs", "Document auth API...", "general-purpose"
)

# Delegate all in parallel (single message, multiple Task calls)
Task(prompt=auth_prompt, description=f"{auth_id}: Implement auth")
Task(prompt=test_prompt, description=f"{test_id}: Write tests")
Task(prompt=docs_prompt, description=f"{docs_id}: Update docs")

# Retrieve results independently (order doesn't matter)
auth_result = get_results_by_task_id(sdk, auth_id, timeout=120)
test_result = get_results_by_task_id(sdk, test_id, timeout=120)
docs_result = get_results_by_task_id(sdk, docs_id, timeout=120)
```

## Spawning Individual AI Agents

### HeadlessSpawner API Reference

```python
from htmlgraph.orchestration import HeadlessSpawner

spawner = HeadlessSpawner()

# spawn_claude() - Strategic reasoning and complex analysis
result = spawner.spawn_claude(
    prompt="Analyze this architecture and recommend improvements",
    permission_mode="plan",  # Options: bypassPermissions, acceptEdits, dontAsk, default, plan, delegate
    output_format="json",
    timeout=300
)
if result.success:
    print(result.response)
    print(f"Tokens used: {result.tokens_used}")

# spawn_gemini() - Quick analysis, multimodal
result = spawner.spawn_gemini(
    prompt="Analyze this code for performance issues",
    model="gemini-2.0-flash",
    include_directories=["src/"],
    output_format="json"
)

# spawn_codex() - Code generation, debugging
result = spawner.spawn_codex(
    prompt="Fix this bug: [description]",
    sandbox="workspace-write",
    output_json=True,
    approval="never"
)

# spawn_copilot() - GitHub workflows
result = spawner.spawn_copilot(
    prompt="Analyze this PR and suggest improvements",
    allow_tools=["shell(git)", "read(*.py)"],
    timeout=120
)
```

## Integration Patterns

### Pattern 1: Parallel Independent Tasks (spawn)
```python
# Good for: Analyzing multiple files, independent checks
# Use: spawn_codex or spawn_gemini
# Cost: Linear (pay per spawn)
# Speed: Parallel execution
# Context: No sharing between tasks

spawner = HeadlessSpawner()
results = []
for file in files:
    result = spawner.spawn_codex(f"Analyze {file} for issues")
    results.append(result)
```

### Pattern 2: Sequential Dependent Tasks (Task)
```python
# Good for: Feature implementation with dependencies
# Use: Task() tool
# Cost: Logarithmic (cache hits on related work)
# Speed: Sequential
# Context: Fully shared

Task(prompt="Implement feature X step 1")
# Shares context with previous work
Task(prompt="Implement feature X step 2, building on step 1")
# Cache hit - 5x cheaper
```

### Pattern 3: Parallel Delegation with Coordination
```python
# Good for: Complex projects with independent work streams
# Use: spawn_* spawners + parallel Task() calls
# Cost: Mixed (parallel isolation + coordination)
# Speed: Parallel + sequential
# Context: Isolated per task, aggregated at orchestrator

# Spawn 3 independent workers
for i in range(3):
    result = spawner.spawn_codex(f"Implement feature {i}")
    save_to_htmlgraph(result)  # Orchestrator saves

# Then sequence dependent work
Task(prompt="Integrate all features and run tests")
```

### Pattern 4: Multi-Provider Specialization
```python
# Good for: Leveraging different provider strengths
# Use: spawn_codex (code) + spawn_gemini (analysis) + spawn_claude (strategy)

# Code implementation
code_result = spawner.spawn_codex("Implement authentication")

# Quick analysis
analysis = spawner.spawn_gemini("Check code for security issues")

# Strategic decision
decision = spawner.spawn_claude("Given the implementation and analysis, what's next?")

# Orchestrator integrates results
final_plan = integrate_results(code_result, analysis, decision)
```

## Operational Guidelines

### Orchestrator Responsibilities
1. **Strategic Planning** - Decide what to build and sequence
2. **Task Decomposition** - Break complex work into delegatable pieces
3. **Agent Selection** - Choose right spawner/tool for each task
4. **Parallel Coordination** - Spawn independent work in parallel
5. **Result Integration** - Aggregate findings and make next decisions
6. **Quality Gates** - Validate results before committing
7. **HtmlGraph Tracking** - Record all work items and completion

### Non-Orchestrator Responsibilities (Delegated)
- Git operations (add, commit, push, merge)
- Code implementation details
- Research and exploration
- Test execution and debugging
- Build and deployment

### Context Management
- Maintain ≥90% context retention for strategic activities
- Batch independent tasks (spawn in parallel)
- Use Task() for dependent sequential work
- Save all results to HtmlGraph for continuity

## Success Metrics

✅ **Effective Orchestration:**
- Delegation reduces tool calls (5-10 direct calls → 2-3 delegation calls)
- Parallel work completes faster
- Strategic context preserved
- All work tracked in HtmlGraph
- Decision clarity maintained

❌ **Anti-Patterns to Avoid:**
- Cascading tool calls (8+ in sequence)
- Lost context between operations
- Untracked delegated work
- Mixing tactical execution with strategy
- Ignoring error handling in direct execution

---

## 4. KEY IMPLEMENTATION NOTES

### System Prompt Deployment

**Option 1: Replace Entire System Prompt**
```bash
claude --system-prompt "$(cat orchestrator-system-prompt.txt)" -p "Your task..."
```
Use the full 2500-token prompt as-is.

**Option 2: Append to Existing Context**
```bash
claude --append-system-prompt "$(cat orchestrator-directives.txt)" -p "Your task..."
```
Can use condensed version (key sections + decision trees).

**Option 3: Environment Variable**
```bash
export CLAUDE_SYSTEM_PROMPT="$(cat orchestrator-system-prompt.txt)"
claude -p "Your task..."
```

### Integration with Claude Code

The prompt works with:
- `/spawn` - Use with HtmlGraph SDK to coordinate work
- `/task` - Delegation task tool
- `/sync` - Session synchronization
- `/doctor` - Orchestrator diagnostics

### Token Budget Optimization

**Average Orchestrator Interaction:**
- System prompt: 500 tokens (reused if cached)
- Single decision: 200-400 tokens
- Delegation instruction: 300-600 tokens
- Total per orchestration cycle: 1-2K tokens

**Cost Savings Through Delegation:**
- Direct execution failing: 5-10K tokens (with retries)
- Delegation with Task(): 1-2K tokens (cached + error handling in subagent)
- Savings: 5-8x token reduction

### Plugin Integration

HtmlGraph plugin provides:
- `HeadlessSpawner` class (orchestration/headless_spawner.py)
- Task coordination helpers (orchestration/task_coordination.py)
- Orchestrator hooks for reflections and validation
- Pre-built spawning patterns

## 5. QUICK REFERENCE

### Spawner Selection Cheat Sheet

| Task Type | Spawner | Key Setting | Example |
|-----------|---------|-------------|---------|
| Code gen | spawn_codex | sandbox="workspace-write" | Bug fix, feature coding |
| Image analysis | spawn_gemini | (native support) | Screenshot analysis |
| GitHub work | spawn_copilot | allow_tools=["shell(git)"] | PR review, branch ops |
| Strategy | spawn_claude | permission_mode="plan" | Architecture, priorities |
| Quick check | spawn_gemini | (fast, cheap) | Syntax, validation |

### Quick Spawn Examples

```python
# Code generation
spawner.spawn_codex("Fix the bug in auth.py")

# Image analysis
spawner.spawn_gemini("What's wrong with this screenshot?", include_directories=["docs/"])

# GitHub workflow
spawner.spawn_copilot("Review this PR and list issues", allow_tools=["read(*.py)", "shell(git)"])

# Strategic thinking
spawner.spawn_claude("Design the deployment architecture", permission_mode="plan")

# Parallel analysis
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor() as executor:
    results = [executor.submit(spawner.spawn_gemini, f"Analyze {f}") for f in files]
```

## 6. VALIDATION CHECKLIST

Before delegating work:
- [ ] Task is independent or in managed sequence
- [ ] Clear success criteria defined
- [ ] Error handling planned
- [ ] Results tracked in HtmlGraph
- [ ] Spawner choice justified
- [ ] Permission modes appropriate
- [ ] Timeout values reasonable
- [ ] Cost implications understood

Before committing results:
- [ ] Validation passed (if applicable)
- [ ] Results linked to work items
- [ ] Session saved to HtmlGraph
- [ ] Next steps identified
- [ ] Quality gates met

            </div>
        </section>
    </article>
</body>
</html>
