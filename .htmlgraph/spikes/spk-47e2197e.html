<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="htmlgraph-version" content="1.0">
    <title>API Refactor Phase 3: Tests & Acceptance Criteria Preparation</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <article id="spk-47e2197e"
             data-type="spike"
             data-status="todo"
             data-priority="medium"
             data-created="2026-02-03T23:21:25.507341"
             data-updated="2026-02-03T23:21:25.507344" data-spike-type="general" data-timebox-hours="4" data-agent-assigned="claude">

        <header>
            <h1>API Refactor Phase 3: Tests & Acceptance Criteria Preparation</h1>
            <div class="metadata">
                <span class="badge status-todo">Todo</span>
                <span class="badge priority-medium">Medium Priority</span>
            </div>
        </header>

    
        <section data-spike-metadata>
            <h3>Spike Metadata</h3>
            <dl>
                <dt>Type</dt>
                <dd>General</dd>
                <dt>Timebox</dt>
                <dd>4 hours</dd>
            </dl>
        </section>
        <section data-findings>
            <h3>Findings</h3>
            <div class="findings-content">
                # Phase 3: Tests & Acceptance Criteria Preparation - COMPLETE

## Status: READY FOR EXECUTION

All planning, fixtures, test templates, and execution guides prepared for Phase 3.

## Documents Created

### 1. Planning & Strategy
- ✅ PHASE3_TESTING_PLAN.md (Comprehensive testing strategy)
  - Unit test design (repositories, services, models)
  - Integration test design (endpoints, WebSocket, cache)
  - E2E test scenarios
  - Performance benchmarking targets (25-40% improvement)
  - Test execution timeline (5-7 days)
  
- ✅ PHASE3_ACCEPTANCE_CRITERIA.md (Measurable criteria)
  - 6 acceptance criteria with specific targets
  - Verification steps for each criterion
  - Test coverage specifications
  - Summary verification checklist
  
- ✅ PHASE3_EXECUTION_GUIDE.md (Step-by-step execution)
  - Phase 3a: Unit Tests (Days 1-2)
  - Phase 3b: Integration Tests (Days 2-3)
  - Phase 3c: Manual Testing (Days 4-5)
  - Phase 3d: Code Quality (Day 5-6)
  - Phase 3e: Documentation (Day 6-7)
  - Detailed bash commands for each task
  - Success criteria for each phase
  - Troubleshooting guide
  
- ✅ PHASE3_READINESS_SUMMARY.md (Readiness overview)
  - What's been prepared (4 categories)
  - Test coverage targets (85%+)
  - Key files created
  - Next steps checklist
  - Risk assessment
  - Timeline (5-7 days total)

## Test Infrastructure Created

### 1. Test Fixtures (conftest.py)
- Database fixtures (sync/async with HtmlGraphDB schema)
- Repository fixtures for all 3 repositories
- Service fixtures for all 3 services
- Cache fixture (QueryCache)
- TestClient fixture for integration tests
- Data factories:
  - EventFactory (100+ events)
  - FeatureFactory (20+ features)
  - SessionFactory (10+ sessions)

### 2. Repository Tests (test_repositories.py)
- EventsRepository: 7 test cases (CRUD, pagination, filtering)
- FeaturesRepository: 7 test cases (CRUD, filtering, status updates)
- SessionsRepository: 7 test cases (CRUD, filtering, status updates)
- Error handling: 3 test cases (invalid IDs, connection errors, rollback)
- Total: ~24 test cases

### 3. Service Tests (test_services.py)
- ActivityService: 7 test cases (grouping, caching, filtering, bulk queries)
- OrchestrationService: 4 test cases (chain detection, dependencies, cost)
- AnalyticsService: 4 test cases (cost summary, metrics, aggregation)
- Cache behavior: 2 test cases (invalidation, TTL)
- Error handling: 2 test cases (database errors, missing data)
- Total: ~19 test cases

## Acceptance Criteria Overview

### Criterion 1: Code Organization
Target: main.py <500 lines (from 2761)
- All SQL queries → repositories
- All business logic → services
- All models → schemas.py
Verification: Automated grep + line count

### Criterion 2: API Backward Compatibility
Target: 100% response shape match, ±10% response time
- GET / unchanged
- GET /api/events unchanged
- GET /api/sessions unchanged
- All endpoints unchanged
Verification: Integration tests + baseline comparison

### Criterion 3: Database Architecture
Target: 100% FastSQLA usage, 0 raw aiosqlite outside repositories
- FastSQLA for all sessions
- aiosqlite only in repositories
- Proper connection pooling
- 5000ms busy timeout
Verification: Grep + unit tests

### Criterion 4: Caching Strategy
Target: fastapi-cache2 usage, >80% hit rate, <50MB overhead
- @cache decorator on endpoints
- QueryCache removed from routes
- Cache TTL configurable
- Cache invalidation on changes
Verification: Integration tests + performance metrics

### Criterion 5: Query Performance
Target: 25%+ improvement (200ms→150ms activity feed)
- Activity feed: <150ms (was 200ms)
- Agent stats: <120ms (was 150ms)
- Orchestration: <180ms (was 250ms)
- WebSocket: <30ms (was 50ms)
- No N+1 queries
Verification: Benchmark tests + query analysis

### Criterion 6: WebSocket Performance
Target: <30ms latency, 0 connection leaks, stable memory
- Connection reuse (no new per cycle)
- <30ms message latency
- Memory stable (<10MB growth/hour)
- Graceful reconnection
- <5s error recovery
Verification: Performance tests + monitoring

## Test Coverage Targets

Component          | Target | Tests | Strategy
-------------------|--------|-------|----------
Repositories       | 85%+   | ~50   | Unit + fixtures
Services           | 90%+   | ~40   | Unit + mocks
Endpoints          | 80%+   | ~20   | Integration
Cache              | 85%+   | ~15   | Behavior tests
WebSocket          | 80%+   | ~10   | Performance
Overall            | 85%+   | 2700+ | Full suite

## Execution Timeline (5-7 days)

Phase 3a: Unit Tests (2-3 days)
- Setup test infrastructure
- Run repository tests
- Run service tests
- Achieve 85%+ coverage

Phase 3b: Integration Tests (2-3 days)
- Endpoint tests
- Cache behavior tests
- Backward compatibility verification

Phase 3c: Manual Testing (2-3 days)
- UI testing checklist
- Performance measurement
- Database query analysis
- WebSocket stress testing

Phase 3d: Code Quality (1 day)
- Full test suite: uv run pytest
- Type checking: uv run mypy src/
- Linting: uv run ruff check
- Coverage: >85% target

Phase 3e: Documentation (1 day)
- Results summary
- Deployment checklist
- Release notes
- QA sign-off

## Dependencies

Phase 3 depends on Phase 2 completion:
- ✅ All repositories implemented and working
- ✅ All services implemented and working
- ✅ FastSQLA integration complete
- ✅ fastapi-cache2 integrated

## Next Steps

1. Complete Phase 2 (repositories & services)
2. Verify Phase 2 tests passing
3. Start Phase 3a: Run unit tests
   ```bash
   uv run pytest tests/unit/api/test_repositories.py -v
   uv run pytest tests/unit/api/test_services.py -v
   ```
4. Track progress through Phase 3e
5. Upon completion: Version bump to 0.29.0, deploy to PyPI

## Success Metrics (Phase 3 Complete)

- [ ] 2665+ tests passing
- [ ] >85% code coverage
- [ ] 0 type errors (mypy)
- [ ] 0 lint warnings (ruff)
- [ ] Performance improvements verified (25%+)
- [ ] 100% backward compatibility
- [ ] All manual tests complete
- [ ] Documentation complete
- [ ] QA sign-off obtained
- [ ] Ready for v0.29.0 deployment

## Files Created

tests/unit/api/
  ✅ conftest.py (Test fixtures & factories)
  ✅ test_repositories.py (Repository unit tests)
  ✅ test_services.py (Service unit tests)

docs/api/
  ✅ PHASE3_TESTING_PLAN.md
  ✅ PHASE3_ACCEPTANCE_CRITERIA.md
  ✅ PHASE3_EXECUTION_GUIDE.md
  ✅ PHASE3_READINESS_SUMMARY.md

## Conclusion

Phase 3 preparation is 100% complete. All infrastructure, tests, and execution plans are ready.

Estimated effort to execute Phase 3: 5-7 days
Estimated completion date: ~2026-02-10

Ready to proceed with Phase 3 upon Phase 2 completion.
            </div>
        </section>
    </article>
</body>
</html>
