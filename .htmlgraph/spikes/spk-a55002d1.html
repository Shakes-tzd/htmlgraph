<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="htmlgraph-version" content="1.0">
    <title>Phase 2 Plan: System Prompt Persistence Layers 2 & 3</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <article id="spk-a55002d1"
             data-type="spike"
             data-status="todo"
             data-priority="high"
             data-created="2026-01-05T03:26:11.089899"
             data-updated="2026-01-05T03:26:11.089902" data-spike-type="general" data-timebox-hours="4" data-agent-assigned="phase2-planner">

        <header>
            <h1>Phase 2 Plan: System Prompt Persistence Layers 2 & 3</h1>
            <div class="metadata">
                <span class="badge status-todo">Todo</span>
                <span class="badge priority-high">High Priority</span>
            </div>
        </header>

        <section data-content>
            <h3>Description</h3>
            <p>
## Phase 2 Implementation Plan - Complete Analysis

### Executive Summary
Comprehensive Phase 2 implementation plan for system prompt persistence Layers 2 & 3 is complete and ready for development. Plan includes detailed architecture, 24 comprehensive tests, parallel implementation streams, and success criteria.

### Key Deliverables

#### 1. Layer 2: CLAUDE_ENV_FILE Implementation (3 days)
- Design: Environment variable persistence mechanism
- Implementation: CLAUDE_ENV_FILE write logic in SessionStart hook
- Configuration written:
  - CLAUDE_SESSION_PROMPT_INJECTED=true
  - CLAUDE_PREFERRED_MODEL=haiku
  - CLAUDE_DELEGATE_SCRIPT (path)
  - HTMLGRAPH_PROJECT_ROOT
  - Session metadata (source, id)
- Cost: 0 tokens | Reliability: 95% | Latency: <5ms
- 4 unit tests covering: basic write, preservation, missing env, directory creation

#### 2. Layer 3: File Backup Implementation (3 days)
- Design: Persistent JSON backup to .claude/session-state.json
- Structure: Session metadata, prompt metrics, persistence state, recovery info
- Content includes:
  - Session ID, source, timestamp
  - Prompt file existence, size, hash, token count
  - Layer success/failure status with timing
  - Recovery information and last known good state
- Cost: 0 tokens | Reliability: 99% | Latency: <10ms
- 4 unit tests covering: basic backup, metrics, recovery preservation, error handling
- Recovery mechanism: Detects Layer 1 failures, attempts restoration

#### 3. Integration Testing (3 days)
- 12 comprehensive integration tests:
  - Compact/resume cycles (all layers)
  - Layer 1 failure → fallback to Layer 2/3
  - Clear command restoration
  - Resume cycle restoration
  - Multi-session continuity
  - Performance benchmarking
- 4 end-to-end tests with real session simulation
- Total: 20 tests covering all scenarios

#### 4. Fallback Chain Logic
Flow:
```
SessionStart Hook → Layer 1 (inject prompt)
                 → Layer 2 (write env file)
                 → Layer 3 (backup to JSON)
                 → Recovery detection (if L1 failed)
```

- All layers execute in sequence
- Each layer is non-blocking (failures don't stop hook)
- Fallback activation: Automatic on next SessionStart if Layer 1 failed
- Effective reliability: 99.99% (only possible if all 3 layers fail simultaneously)

### Architecture Decisions

#### Decision 1: Why CLAUDE_ENV_FILE for Layer 2?
- Selected over: Claude settings.json, direct env vars, custom config
- Rationale: 0 token cost, available in bash, simple, proven reliable
- Trade-off: Requires Claude Code support (acceptable)

#### Decision 2: Why .claude/session-state.json for Layer 3?
- Selected over: .htmlgraph logs, transcript analysis, binary cache
- Rationale: Human-readable, diagnostic value, optional git tracking
- Trade-off: Small file addition (negligible)

#### Decision 3: Why JSON (not YAML)?
- Rationale: Native Python, no dependencies, standard in HtmlGraph

### Parallel Implementation Streams

**Stream 1 (Layer 2):** 3 days - Environment variable persistence
**Stream 2 (Layer 3):** 3 days - File backup implementation
**Stream 3 (Integration):** 3 days - Testing and validation
**Stream 4 (Docs):** 2-3 days - Documentation and validation

**Critical Path:** Streams 1 & 2 must complete before Stream 3 fully starts, but can proceed independently. Stream 4 can begin after other streams in parallel.

**Timeline Compression:** 8-10 calendar days possible with parallel execution (11-12 person-days total).

### Testing Strategy

**Unit Tests (8):**
- Layer 2: Basic write, preservation, error handling, directory creation
- Layer 3: Backup write, metrics, recovery preservation, error handling
- Coverage target: 95%+ of code paths
- Execution: <5 seconds

**Integration Tests (12):**
- Layers 1-2-3 together
- Compact/resume/clear cycles
- Fallback activation scenarios
- Coverage: All happy paths + 5 failure scenarios
- Execution: <30 seconds

**End-to-End Tests (4):**
- Real Claude Code simulation
- Full lifecycle testing
- Metrics validation
- Execution: <60 seconds

**Performance Benchmarks:**
- Layer 2: <10ms target
- Layer 3: <15ms target
- Combined hook: <60ms target
- Stress test with large prompts: <80ms

### Quality Gates

Before merge:
- All 24 tests passing (100% pass rate)
- Code coverage >90% (Layer 2 & 3)
- mypy strict mode: 0 errors
- ruff linting: 0 violations
- Performance targets met
- No regressions from Phase 1

### Risk Assessment (Overall: LOW)

**Risk 1:** CLAUDE_ENV_FILE unavailable
- Probability: 5% | Impact: Medium | Mitigation: Graceful failure, Layers 1 & 3 work

**Risk 2:** File system errors during Layer 3
- Probability: 1% | Impact: Low | Mitigation: Non-blocking, try-except

**Risk 3:** Hook timeout
- Probability: 0.1% | Impact: Medium | Mitigation: <60ms target, well under 30s timeout

**Risk 4:** Concurrent hook execution
- Probability: 2-5% | Impact: Low | Mitigation: Atomic operations, idempotent design

**Risk 5:** Large prompt issues
- Probability: 1-2% | Impact: Low | Mitigation: Validation, truncation, warning

### Monitoring & Observability

**Per-Session Metrics:**
- Layer 1: success, latency_ms, tokens_injected
- Layer 2: success, latency_ms, env_vars_written
- Layer 3: success, latency_ms, backup_size_bytes
- Effective reliability percentage

**Aggregate Metrics (7-day rolling):**
- Layer 1 success rate (target: >99%)
- Layer 2 success rate (target: >95%)
- Layer 3 success rate (target: >99%)
- Effective reliability (target: >99.99%)
- Average/P95/P99 hook latencies

**Alert Triggers:**
- L1 success <95% → Layer 1 issue
- L2 success <85% → CLAUDE_ENV_FILE issue
- L3 success <95% → File system issue
- Hook latency >100ms → Performance degradation

### Documentation Deliverables

1. **Hook Documentation Update**
   - Layer 2 & 3 mechanisms
   - Environment variables set
   - Configuration examples

2. **System Prompt Persistence Guide Update**
   - Layer 2 environment support
   - Usage examples in bash

3. **Troubleshooting Guide (NEW)**
   - Layer 2: CLAUDE_ENV_FILE issues
   - Layer 3: Backup file issues
   - Recovery procedures

4. **Admin Guide (NEW)**
   - Monitoring setup
   - Alert configuration
   - Diagnostic commands

### Success Criteria Checklist

**Implementation:**
- [ ] Layer 2 complete and tested
- [ ] Layer 3 complete and tested
- [ ] 24 tests passing (8 unit + 12 integration + 4 E2E)
- [ ] Code coverage >90%
- [ ] mypy strict: 0 errors
- [ ] ruff linting: 0 violations

**Performance:**
- [ ] Layer 2 <10ms average
- [ ] Layer 3 <15ms average
- [ ] Combined hook <60ms
- [ ] Stress test <80ms

**Documentation:**
- [ ] Hook docs updated
- [ ] Troubleshooting guide complete
- [ ] Admin guide created
- [ ] Recovery procedures documented

**Validation:**
- [ ] Real Claude Code testing complete
- [ ] Compact/resume cycle verified
- [ ] Clear command verified
- [ ] Fallback chain verified
- [ ] Metrics collection working

**Integration:**
- [ ] Merged to main
- [ ] CI/CD passing
- [ ] No Phase 1 regressions
- [ ] Ready for Phase 3

### File Changes Summary

**New Files:**
- tests/hooks/test_system_prompt_persistence_phase2.py (24 tests)
- docs/SYSTEM_PROMPT_PERSISTENCE_ADMIN_GUIDE.md
- Benchmark report (performance metrics)

**Updated Files:**
- packages/claude-plugin/hooks/scripts/session-start.py (+300-400 lines)
- docs/SYSTEM_PROMPT_PERSISTENCE_GUIDE.md (Layer 2/3 sections)
- packages/claude-plugin/hooks/README.md (Layer 2/3 docs)

### Resource Allocation

| Role | Stream | Days | Effort |
|------|--------|------|--------|
| Backend Dev | Layer 2 | 3 | 3 days |
| Backend Dev | Layer 3 | 3 | 3 days |
| QA Engineer | Integration | 3 | 3 days |
| Tech Writer | Documentation | 2-3 | 2-3 days |

**Total:** 11-12 person-days (8-10 calendar days with parallelization)

### Implementation Order (Critical Path)

1. Day 1-2: Parallel Layer 2 & 3 implementation
2. Day 2-3: Unit testing (4 tests each layer)
3. Day 3-4: Integration testing (all layers)
4. Day 4-5: Performance optimization, edge cases
5. Day 5: Documentation, final validation, merge readiness

### Phase 2 vs Phase 1 Comparison

| Aspect | Phase 1 | Phase 2 |
|--------|---------|---------|
| Mechanism | additionalContext injection | Env file + file backup |
| Cost | 250-500 tokens | 0 tokens |
| Reliability | 99.9% | 99% + 95% (3-layer 99.99%) |
| Latency | <50ms | <20ms total |
| Tests | 12 | 24 |
| Documentation | User guide | Admin guide |
| Fallback | Default prompt | Layer 2/3 + recovery |

### Connection to Phase 3

Phase 2 completion enables Phase 3:
- Layer 2 env vars available for delegate.sh script
- Session state backup enables model-aware decisions
- Reliable persistence enables explicit Haiku preference signaling

### Key Implementation Details

**Layer 2 Pseudo-Code:**
```python
env_file = os.environ.get("CLAUDE_ENV_FILE")
if env_file:
    # Read existing content
    # Remove CLAUDE_* vars
    # Add new vars: CLAUDE_SESSION_PROMPT_INJECTED, CLAUDE_PREFERRED_MODEL, etc.
    # Write atomic update
```

**Layer 3 Pseudo-Code:**
```python
state = {
    "version": "1.0",
    "session": {...session metadata...},
    "prompt": {...prompt metrics...},
    "persistence": {...layer status/timing...},
    "recovery_info": {...recovery state...}
}
backup_file.write_text(json.dumps(state, indent=2))
```

### Integration Points

**With HtmlGraph:**
- Session tracking (Phase 4)
- Analytics dashboard (monitoring metrics)
- Feature attribution (preserve across compacts)
- Activity history (record injection events)

**With Orchestrator Mode:**
- Layer 2 env file provides model preference
- System prompt provides delegation instructions
- Both together enable proper delegation workflows

### Open Questions Resolved

Q: Will Layer 2 work if CLAUDE_ENV_FILE isn't set?
A: Yes. It's optional; hook continues. Layers 1 & 3 still work.

Q: Can users see the backup file?
A: Yes. It's human-readable JSON and can be committed to git.

Q: What happens if hook crashes during Layer 3?
A: Non-blocking try-except; hook continues and exits cleanly.

Q: How do we know if fallback is needed?
A: Layer 1 injection checked in next SessionStart; recorded in backup.

Q: Performance impact of all three layers?
A: <60ms combined (well under 30s timeout). Negligible.

### Completion Status

All research complete. Implementation plan fully specified with:
- Detailed architecture and design decisions
- 24 comprehensive tests specified
- Parallel implementation streams defined
- Quality gates established
- Risk assessment complete
- Documentation plan ready
- Success criteria checklist prepared

Ready to proceed to implementation phase.
</p>
        </section>
    
        <section data-spike-metadata>
            <h3>Spike Metadata</h3>
            <dl>
                <dt>Type</dt>
                <dd>General</dd>
                <dt>Timebox</dt>
                <dd>4 hours</dd>
            </dl>
        </section>
    </article>
</body>
</html>
